// Converts a Char to its binary representation.
// - char: Input Char.
// = Binary representation as Bits.
Char/to-bits : Char -> Bits
| char = (Bits/pad-zeros (U64/to-bits char) #21)

#test: (Char/to-bits 'A') == (Bits/pad-zeros (U64/to-bits 65) #21)
#test: (Char/to-bits '\0') == (Bits/pad-zeros (U64/to-bits 0) #21)
#test: (Char/to-bits '~') == (Bits/pad-zeros (U64/to-bits 126) #21)
#test: (Bits/eq (Char/to-bits 'a') (Char/to-bits 'a')) == #True
#test: (Bits/eq (Char/to-bits 'a') (Char/to-bits 'b')) == #False